{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from scipy.sparse import issparse\n",
    "import pandas as pd\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (25, 13)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 20\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Featurizer:\n",
    "\n",
    "    class InvalidTag(Exception):\n",
    "        pass\n",
    "\n",
    "    tag_re = re.compile(r'^[A-Z]+')\n",
    "\n",
    "    def __init__(self, last_char, N, data_path, full_tag=False,\n",
    "                 use_padding=True,\n",
    "                 use_word_as_feature=False, tag_filter=None,\n",
    "                 include_smaller_ngrams=False,\n",
    "                 encoding='utf-8',\n",
    "                 sample_per_class=100,\n",
    "                 max_lines=2000000,\n",
    "                 **kwargs):\n",
    "        self.last_char = last_char\n",
    "        self.N = N\n",
    "        self.full_tag = full_tag\n",
    "        self.use_padding = use_padding\n",
    "        self.use_word_as_feature = use_word_as_feature\n",
    "        self.include_smaller_ngrams = include_smaller_ngrams\n",
    "        self.data_path = data_path\n",
    "        self.sample_per_class = sample_per_class\n",
    "        self.max_lines = max_lines\n",
    "        self.encoding = encoding\n",
    "        if tag_filter is not None:\n",
    "            self.tag_filter = set(tag_filter)\n",
    "        else:\n",
    "            self.tag_filter = None\n",
    "        self.raw_input = []\n",
    "\n",
    "    def featurize(self):\n",
    "        X = []\n",
    "        y = []\n",
    "        sample_cnt = defaultdict(int)\n",
    "        line_cnt = 0\n",
    "        with open(self.data_path, encoding=self.encoding) as f:\n",
    "            for line in f:\n",
    "                line_cnt += 1\n",
    "                if self.max_lines > 0 and line_cnt > self.max_lines:\n",
    "                    break\n",
    "                try:\n",
    "                    word, tag = self.extract_word_and_tag(line)\n",
    "                except Featurizer.InvalidTag:\n",
    "                    continue\n",
    "                if not word.strip() or not tag.strip():\n",
    "                    continue\n",
    "                if self.tag_filter is not None and tag not in self.tag_filter:\n",
    "                    continue\n",
    "                if self.sample_per_class > 0 and \\\n",
    "                    (all(v >= self.sample_per_class\n",
    "                         for v in sample_cnt.values()) and\n",
    "                     len(sample_cnt) > 1):\n",
    "                    break\n",
    "                sample_cnt[tag] += 1\n",
    "                if sample_cnt[tag] > self.sample_per_class:\n",
    "                    continue\n",
    "                self.__featurize_and_store_sample(word, tag, X, y)\n",
    "                self.raw_input.append((word, tag))\n",
    "        return self.create_feature_matrix(X, y)\n",
    "\n",
    "    def create_feature_matrix(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.X_mtx = self.__get_or_create_vectorizer('X_vectorizer', X)\n",
    "        self.y_vec = self.__get_or_create_vectorizer('y_vectorizer', y)\n",
    "        return self.X_mtx, self.y_vec\n",
    "    \n",
    "    def create_train_test(self, ratio):\n",
    "        Xtr, Xte, ytr, yte = train_test_split(self.X_mtx, self.y_vec, train_size=ratio)\n",
    "        self.X_train = Xtr\n",
    "        self.X_test = Xte\n",
    "        self.y_train = ytr\n",
    "        self.y_test = yte\n",
    "        \n",
    "\n",
    "    def __get_or_create_vectorizer(self, name, data):\n",
    "        if not hasattr(self, name):\n",
    "            dv = DictVectorizer()\n",
    "            v = dv.fit_transform(data)\n",
    "            setattr(self, name, dv)\n",
    "        return v\n",
    "\n",
    "    def extract_word_and_tag(self, line):\n",
    "        fd = line.strip().split('\\t')\n",
    "        word = fd[0]\n",
    "        tag = fd[-1].split('/')[-1]\n",
    "        if self.full_tag is False:\n",
    "            try:\n",
    "                tag = Featurizer.tag_re.match(tag).group(0)\n",
    "            except AttributeError:\n",
    "                raise Featurizer.InvalidTag()\n",
    "        return word, tag\n",
    "\n",
    "    def __featurize_and_store_sample(self, word, tag, X, y):\n",
    "        if self.use_word_as_feature:\n",
    "            f = {'word': word}\n",
    "        else:\n",
    "            f = self.__featurize_ngram(word)\n",
    "        X.append(f)\n",
    "        y.append({'class': tag})\n",
    "\n",
    "    def __featurize_ngram(self, word):\n",
    "        feats = {}\n",
    "        if self.last_char > 0:\n",
    "            word = word[-self.last_char:]\n",
    "        if self.include_smaller_ngrams:\n",
    "            for n in range(1, self.N+1):\n",
    "                feats.update(Featurizer.extract_ngrams(\n",
    "                    word, n, self.use_padding))\n",
    "        else:\n",
    "            feats.update(Featurizer.extract_ngrams(\n",
    "                word, self.N, self.use_padding))\n",
    "        return feats\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_ngrams(text, N, padding=False):\n",
    "        if padding is True:\n",
    "            text = '{0}{1}{0}'.format(\" \" * (N-1), text)\n",
    "        feats = {}\n",
    "        for i in range(len(text)-N+1):\n",
    "            feats['{0}_{1}'.format(N, i)] = text[i:i+N]\n",
    "        return feats\n",
    "\n",
    "    def get_theoretical_max(self):\n",
    "        samples = defaultdict(lambda: defaultdict(int))\n",
    "        for i in range(len(self.X)):\n",
    "            xi = self.X[i]\n",
    "            yi = self.y[i]\n",
    "            f_str = ','.join('{}:{}'.format(feat, val)\n",
    "                             for feat, val in sorted(xi.items()))\n",
    "            samples[f_str][yi['class']] += 1\n",
    "        return sum(max(v.values()) for v in samples.values()) / len(self.X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class FFNN:\n",
    "    @staticmethod\n",
    "    def create_list_if_str(param, length):\n",
    "        if isinstance(param, str):\n",
    "            return [param] * length\n",
    "        return param\n",
    "    \n",
    "    def __init__(self, layers, activations, input_dim, output_dim, *,\n",
    "                 loss='binary_crossentropy', optimizer='rmsprop', metrics=['accuracy'],\n",
    "                nb_epoch=50, batch_size=50, **kwargs):\n",
    "        self.layers = layers\n",
    "        self.activations = FFNN.create_list_if_str(activations, len(self.layers) + 1)\n",
    "        self.input_dim = input_dim\n",
    "        self.output_dim = output_dim\n",
    "        self.model_fit_args = {\n",
    "            'nb_epoch': nb_epoch,\n",
    "            'batch_size': batch_size,\n",
    "        }\n",
    "        self.model_compile_args = {\n",
    "            'optimizer': optimizer,\n",
    "            'metrics': metrics,\n",
    "            'loss': loss,\n",
    "        }\n",
    "        self.create_network()\n",
    "        \n",
    "    def create_network(self):\n",
    "        self.model = Sequential()\n",
    "        # input layer\n",
    "        self.model.add(Dense(self.layers[0], input_dim=self.input_dim, activation=self.activations[0]))\n",
    "        for i in range(1, len(self.layers)):\n",
    "            self.model.add(Dense(self.layers[i], activation=self.activations[i]))\n",
    "        #output layer\n",
    "        self.model.add(Dense(self.output_dim, activation=self.activations[-1]))\n",
    "        self.model.compile(**self.model_compile_args)\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        X = FFNN.densify(X)\n",
    "        y = FFNN.densify(y)\n",
    "        start = datetime.now()\n",
    "        self.model.fit(X, y, verbose=0, **self.model_fit_args)\n",
    "        return datetime.now() - start\n",
    "        \n",
    "    def evaluate(self, X, y, **kwargs):\n",
    "        X = FFNN.densify(X)\n",
    "        y = FFNN.densify(y)\n",
    "        return self.model.evaluate(X, y, **kwargs)\n",
    "    \n",
    "    @staticmethod\n",
    "    def densify(mtx):\n",
    "        if issparse(mtx):\n",
    "            return mtx.todense()\n",
    "        return mtx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Config:\n",
    "    def __init__(self, conf_d):\n",
    "        self.glob_conf = Config.defaults.get('global', {})\n",
    "        self.feat_conf = Config.defaults.get('featurizer', {})\n",
    "        self.model_conf = Config.defaults.get('model', {})\n",
    "        \n",
    "        self.glob_conf.update(conf_d.get('global', {}))\n",
    "        self.feat_conf.update(conf_d.get('featurizer', {}))\n",
    "        self.model_conf.update(conf_d.get('model', {}))\n",
    "        \n",
    "    def to_dict(self):\n",
    "        d = {}\n",
    "        d.update(self.serialize_config(self.glob_conf, 'global'))\n",
    "        d.update(self.serialize_config(self.feat_conf, 'feat'))\n",
    "        d.update(self.serialize_config(self.model_conf, 'model'))\n",
    "        return d\n",
    "        \n",
    "    def serialize_config(self, section, pre):\n",
    "        d = {}\n",
    "        for k, v in section.items():\n",
    "            d['{0}.{1}'.format(pre, k)] = v\n",
    "        return d\n",
    "        \n",
    "    defaults = {\n",
    "        'global': {\n",
    "            'train_test_split': .9,\n",
    "            'nolog': False,\n",
    "        },\n",
    "        'model': {\n",
    "            'loss': 'binary_crossentropy',\n",
    "            'optimizer': 'rmsprop',\n",
    "            'metrics': ['accuracy'],\n",
    "            'nb_epoch': 50,\n",
    "            'batch_size': 64,\n",
    "        },\n",
    "        'featurizer': {\n",
    "            'data_path': '/mnt/store/hlt/Language/Hungarian/Crawl/Web2/ana/xaa.tagged',\n",
    "            'encoding': 'latin2',\n",
    "            'include_smaller_ngrams': False,\n",
    "            'use_padding': True,\n",
    "            'tag_filter': (\"NOUN\", \"VERB\"),\n",
    "        },\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Result:\n",
    "    __slots__ = ('train_sample_count', 'test_sample_count', 'feature_count',\n",
    "                 'success', 'exception',\n",
    "                 'running_time', 'timestamp',\n",
    "                 'train_acc', 'test_acc', 'train_loss', 'test_loss')\n",
    "    \n",
    "    def to_dict(self):\n",
    "        d = {}\n",
    "        for k in Result.__slots__:\n",
    "            try:\n",
    "                d['result.{}'.format(k)] = getattr(self, k)\n",
    "            except AttributeError:\n",
    "                d['result.{}'.format(k)] = None\n",
    "        return d\n",
    "    \n",
    "    def __str__(self):\n",
    "        return \"Train accuracy: {}\\nTest accuracy: {}\".format(self.train_acc, self.test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Experiment:\n",
    "    \n",
    "    df_path = 'results.tsv'\n",
    "    \n",
    "    def __init__(self, conf_d):\n",
    "        self.config = Config(conf_d)\n",
    "        self.featurizer = Featurizer(**self.config.feat_conf)\n",
    "        self.featurizer.featurize()\n",
    "        input_dim = self.featurizer.X_mtx.shape[1]\n",
    "        output_dim = self.featurizer.y_vec.shape[1]\n",
    "        self.config.model_conf['input_dim'] = input_dim\n",
    "        self.config.model_conf['output_dim'] = output_dim\n",
    "        self.initialize_model()\n",
    "        self.result = Result()\n",
    "        self.result.feature_count = input_dim\n",
    "        \n",
    "    def initialize_model(self):\n",
    "        if self.config.model_conf['architecture'].lower() == 'ffnn':\n",
    "            self.model = FFNN(**self.config.model_conf)\n",
    "        else:\n",
    "            raise ValueError(\"Model architecture [{}] not supported\".format(\n",
    "                    self.config.model['architecture']))\n",
    "            \n",
    "    def fit_train(self):\n",
    "        self.result.timestamp = datetime.now()\n",
    "        self.featurizer.create_train_test(self.config.glob_conf['train_test_split'])\n",
    "        rt = self.model.fit(self.featurizer.X_train.todense(), self.featurizer.y_train.todense())\n",
    "        self.result.running_time = rt\n",
    "        \n",
    "    def evaluate_train(self):\n",
    "        l =  self.model.evaluate(self.featurizer.X_train, self.featurizer.y_train, batch_size=16)\n",
    "        self.result.train_loss = l[0]\n",
    "        self.result.train_acc = l[1]\n",
    "        self.result.train_sample_count = self.featurizer.X_train.shape[0]\n",
    "        \n",
    "    def evaluate_test(self):\n",
    "        l =  self.model.evaluate(self.featurizer.X_test, self.featurizer.y_test, batch_size=16)\n",
    "        self.result.test_loss = l[0]\n",
    "        self.result.test_acc = l[1]\n",
    "        self.result.test_sample_count = self.featurizer.X_test.shape[0]\n",
    "        \n",
    "    def run_and_save(self):\n",
    "        try:\n",
    "            self.fit_train()\n",
    "            self.evaluate_train()\n",
    "            self.evaluate_test()\n",
    "        except Exception as e:\n",
    "            self.result.success = False\n",
    "            self.result.exception = type(e).__name__\n",
    "        else:\n",
    "            self.result.success = True\n",
    "        if self.config.glob_conf['nolog'] is False:\n",
    "            self.save_results()\n",
    "        \n",
    "    def save_results(self):\n",
    "        d = {}\n",
    "        d.update(self.config.to_dict())\n",
    "        d.update(self.result.to_dict())\n",
    "        Experiment.save_to_dataframe(d, Experiment.df_path)\n",
    "        \n",
    "    @staticmethod\n",
    "    def save_to_dataframe(data, fn):\n",
    "        if os.path.exists(fn):\n",
    "            df = pd.read_table(fn)\n",
    "        else:\n",
    "            df = pd.DataFrame(columns=data.keys())\n",
    "            \n",
    "        new_cols = set(data.keys()) - set(df.columns)\n",
    "        for c in new_cols:\n",
    "            df[c] = None\n",
    "        df = df.append(data, ignore_index=True)\n",
    "        df.to_csv(fn, sep='\\t', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actual experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sgd\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cfg = {\n",
    "    'global': {\n",
    "        'nolog': False,\n",
    "        'comment': \"other optimizers\",\n",
    "    },\n",
    "    'featurizer': {\n",
    "        'last_char': 6,\n",
    "        'N': 2,\n",
    "        'use_padding': True,\n",
    "        'sample_per_class': 30000,\n",
    "        'include_smaller_ngrams': True,\n",
    "        'tag_filter': (\"NOUN\", \"VERB\"),\n",
    "    },\n",
    "    'model': {\n",
    "        'architecture': 'FFNN',\n",
    "        'layers': (40, 40),\n",
    "        'activations': ('sigmoid', 'sigmoid', 'sigmoid'),\n",
    "        'optimizer': 'rmsprop',\n",
    "        'loss': 'binary_crossentropy',\n",
    "        'metrics': ['accuracy'],\n",
    "        'nb_epoch': 300,\n",
    "        'batch_size': 500,\n",
    "    },\n",
    "}\n",
    "\n",
    "optimizers = ['sgd', 'adagrad', 'adam', 'nadam', 'adamax', 'rmsprop']\n",
    "\n",
    "for opt in optimizers:\n",
    "    print(opt)\n",
    "    cfg['model']['optimizer'] = opt\n",
    "    for last_char in range(4, 9):\n",
    "        cfg['featurizer']['last_char'] = last_char\n",
    "        for N in range(1, 3):\n",
    "            cfg['featurizer']['N'] = N\n",
    "            e = Experiment(cfg)\n",
    "            e.run_and_save()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "print(12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
