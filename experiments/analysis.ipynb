{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (25, 13)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 20\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful: 762\n",
      "Failed: 0\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('results.tsv', sep='\\t')\n",
    "print(\"Successful: {}\\nFailed: {}\".format(len(df[df['result.success'] == True]), len(df[df['result.success'] == False])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model.optimizer</th>\n",
       "      <th>result.timestamp</th>\n",
       "      <th>result.test_acc</th>\n",
       "      <th>result.running_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>757</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2016-12-03 04:42:02.647452</td>\n",
       "      <td>0.980083</td>\n",
       "      <td>0 days 00:06:45.157307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2016-12-03 04:49:17.063119</td>\n",
       "      <td>0.978583</td>\n",
       "      <td>0 days 00:01:48.814142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>759</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2016-12-03 04:51:33.885317</td>\n",
       "      <td>0.980083</td>\n",
       "      <td>0 days 00:07:37.258082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>760</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2016-12-03 04:59:41.202131</td>\n",
       "      <td>0.978167</td>\n",
       "      <td>0 days 00:01:49.003291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>761</th>\n",
       "      <td>rmsprop</td>\n",
       "      <td>2016-12-03 05:01:59.111539</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0 days 00:08:26.683645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    model.optimizer            result.timestamp  result.test_acc  \\\n",
       "757         rmsprop  2016-12-03 04:42:02.647452         0.980083   \n",
       "758         rmsprop  2016-12-03 04:49:17.063119         0.978583   \n",
       "759         rmsprop  2016-12-03 04:51:33.885317         0.980083   \n",
       "760         rmsprop  2016-12-03 04:59:41.202131         0.978167   \n",
       "761         rmsprop  2016-12-03 05:01:59.111539         0.980000   \n",
       "\n",
       "        result.running_time  \n",
       "757  0 days 00:06:45.157307  \n",
       "758  0 days 00:01:48.814142  \n",
       "759  0 days 00:07:37.258082  \n",
       "760  0 days 00:01:49.003291  \n",
       "761  0 days 00:08:26.683645  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[-5:][['model.optimizer', 'result.timestamp', 'result.test_acc', 'result.running_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df.sort_values('result.test_acc').tail()[['result.test_acc', 'model.layers'] + feat_uniq_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filtering not so useful experiments\n",
    "\n",
    "* failed experiments\n",
    "* experiments with less than 30000 samples-per-class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering experiments: 702 --> 498\n"
     ]
    }
   ],
   "source": [
    "orig = len(df)\n",
    "df = df[(df['result.success'] == True) & (df['feat.sample_per_class'] >= 30000)]\n",
    "print(\"Filtering experiments: {} --> {}\".format(orig, len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_varying_columns(df, prefix=None):\n",
    "    out_cols = []\n",
    "    filtered_cols = df.columns\n",
    "    if prefix is not None:\n",
    "        filtered_cols = filter(lambda x: x.startswith(prefix), filtered_cols)\n",
    "    for col in filtered_cols:\n",
    "        if df[col].unique().shape[0] > 1:\n",
    "            out_cols.append(col)\n",
    "    return out_cols\n",
    "\n",
    "def get_too_varying_columns(df, prefix=None, threshold=0.95):\n",
    "    out_cols = []\n",
    "    filtered_cols = df.columns\n",
    "    if prefix is not None:\n",
    "        filtered_cols = filter(lambda x: x.startswith(prefix), cols)\n",
    "    for col in filtered_cols:\n",
    "        uniq_vals = df[col].unique().shape[0]\n",
    "        if uniq_vals > threshold * len(df):\n",
    "            out_cols.append(col)\n",
    "    return out_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_uniq_col = get_varying_columns(df, 'feat.')\n",
    "result_uniq_col = get_varying_columns(df, 'result.')\n",
    "model_uniq_col = get_varying_columns(df, 'model.')\n",
    "all_params = feat_uniq_col + model_uniq_col\n",
    "non_monoton = get_varying_columns(df)\n",
    "uninteresting_columns = filter(lambda x: x not in non_monoton, df.columns)\n",
    "ignore_cols = [\n",
    "    'result.train_loss', 'result.test_loss', 'result.timestamp', 'result.running_time',\n",
    "]\n",
    "result_uniq_col = [col for col in result_uniq_col if col not in ignore_cols]\n",
    "interesting_columns = result_uniq_col + feat_uniq_col + model_uniq_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[['result.test_acc'] + all_params].sort_values('result.test_acc', ascending=False).to_csv('results_filtered_columns.tsv', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique feature combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat.last_char</th>\n",
       "      <th>feat.use_padding</th>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <th>feat.N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     feat.last_char feat.use_padding feat.include_smaller_ngrams  feat.N\n",
       "204             6.0             True                       False     1.0\n",
       "336             6.0            False                       False     6.0\n",
       "402             6.0             True                       False     2.0\n",
       "432             6.0             True                        True     2.0\n",
       "472             3.0             True                        True     1.0\n",
       "473             3.0             True                        True     2.0\n",
       "474             3.0             True                        True     3.0\n",
       "475             4.0             True                        True     1.0\n",
       "476             4.0             True                        True     2.0\n",
       "477             4.0             True                        True     3.0\n",
       "478             5.0             True                        True     1.0\n",
       "479             5.0             True                        True     2.0\n",
       "480             5.0             True                        True     3.0\n",
       "481             6.0             True                        True     1.0\n",
       "483             6.0             True                        True     3.0\n",
       "484             7.0             True                        True     1.0\n",
       "485             7.0             True                        True     2.0\n",
       "486             7.0             True                        True     3.0\n",
       "487             8.0             True                        True     1.0\n",
       "488             8.0             True                        True     2.0\n",
       "489             8.0             True                        True     3.0\n",
       "490             9.0             True                        True     1.0\n",
       "491             9.0             True                        True     2.0\n",
       "492             9.0             True                        True     3.0"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[feat_uniq_col].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of experiments per combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model.nb_epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.last_char</th>\n",
       "      <th>feat.use_padding</th>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <th>feat.N</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">3.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">4.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">5.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"6\" valign=\"top\">6.0</th>\n",
       "      <th>False</th>\n",
       "      <th>False</th>\n",
       "      <th>6.0</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>1.0</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">7.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">8.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">9.0</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">True</th>\n",
       "      <th>1.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                    model.nb_epoch\n",
       "feat.last_char feat.use_padding feat.include_smaller_ngrams feat.N                \n",
       "3.0            True             True                        1.0                  1\n",
       "                                                            2.0                  1\n",
       "                                                            3.0                  1\n",
       "4.0            True             True                        1.0                  1\n",
       "                                                            2.0                  1\n",
       "                                                            3.0                  1\n",
       "5.0            True             True                        1.0                  1\n",
       "                                                            2.0                  1\n",
       "                                                            3.0                  1\n",
       "6.0            False            False                       6.0                 66\n",
       "               True             False                       1.0                132\n",
       "                                                            2.0                 30\n",
       "                                True                        1.0                  1\n",
       "                                                            2.0                249\n",
       "                                                            3.0                  1\n",
       "7.0            True             True                        1.0                  1\n",
       "                                                            2.0                  1\n",
       "                                                            3.0                  1\n",
       "8.0            True             True                        1.0                  1\n",
       "                                                            2.0                  1\n",
       "                                                            3.0                  1\n",
       "9.0            True             True                        1.0                  1\n",
       "                                                            2.0                  1\n",
       "                                                            3.0                  2"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(feat_uniq_col).count()['model.nb_epoch'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum test accuracy by feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result.test_acc</th>\n",
       "      <th>feat.last_char</th>\n",
       "      <th>feat.use_padding</th>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <th>feat.N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>0.935833</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>473</th>\n",
       "      <td>0.930333</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>474</th>\n",
       "      <td>0.936000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.966000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>0.971833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>0.972833</td>\n",
       "      <td>4.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>478</th>\n",
       "      <td>0.973250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>0.980000</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>480</th>\n",
       "      <td>0.980083</td>\n",
       "      <td>5.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.819917</td>\n",
       "      <td>6.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.973417</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.979500</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>481</th>\n",
       "      <td>0.979750</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.985333</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0.985000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>484</th>\n",
       "      <td>0.976000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>485</th>\n",
       "      <td>0.982000</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>0.981667</td>\n",
       "      <td>7.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>487</th>\n",
       "      <td>0.975250</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>488</th>\n",
       "      <td>0.980667</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>489</th>\n",
       "      <td>0.984167</td>\n",
       "      <td>8.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>490</th>\n",
       "      <td>0.972750</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>0.980167</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>0.982167</td>\n",
       "      <td>9.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     result.test_acc  feat.last_char feat.use_padding  \\\n",
       "472         0.935833             3.0             True   \n",
       "473         0.930333             3.0             True   \n",
       "474         0.936000             3.0             True   \n",
       "475         0.966000             4.0             True   \n",
       "476         0.971833             4.0             True   \n",
       "477         0.972833             4.0             True   \n",
       "478         0.973250             5.0             True   \n",
       "479         0.980000             5.0             True   \n",
       "480         0.980083             5.0             True   \n",
       "359         0.819917             6.0            False   \n",
       "325         0.973417             6.0             True   \n",
       "429         0.979500             6.0             True   \n",
       "481         0.979750             6.0             True   \n",
       "453         0.985333             6.0             True   \n",
       "483         0.985000             6.0             True   \n",
       "484         0.976000             7.0             True   \n",
       "485         0.982000             7.0             True   \n",
       "486         0.981667             7.0             True   \n",
       "487         0.975250             8.0             True   \n",
       "488         0.980667             8.0             True   \n",
       "489         0.984167             8.0             True   \n",
       "490         0.972750             9.0             True   \n",
       "491         0.980167             9.0             True   \n",
       "492         0.982167             9.0             True   \n",
       "\n",
       "    feat.include_smaller_ngrams  feat.N  \n",
       "472                        True     1.0  \n",
       "473                        True     2.0  \n",
       "474                        True     3.0  \n",
       "475                        True     1.0  \n",
       "476                        True     2.0  \n",
       "477                        True     3.0  \n",
       "478                        True     1.0  \n",
       "479                        True     2.0  \n",
       "480                        True     3.0  \n",
       "359                       False     6.0  \n",
       "325                       False     1.0  \n",
       "429                       False     2.0  \n",
       "481                        True     1.0  \n",
       "453                        True     2.0  \n",
       "483                        True     3.0  \n",
       "484                        True     1.0  \n",
       "485                        True     2.0  \n",
       "486                        True     3.0  \n",
       "487                        True     1.0  \n",
       "488                        True     2.0  \n",
       "489                        True     3.0  \n",
       "490                        True     1.0  \n",
       "491                        True     2.0  \n",
       "492                        True     3.0  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAF2CAYAAAAGIhAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1bcbe19c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_rows = df.loc[df.groupby(feat_uniq_col).idxmax()['result.test_acc'].astype(int)]\n",
    "max_rows.plot(y='result.test_acc', kind='bar', ylim=(0.95, 1))\n",
    "max_rows[['result.test_acc'] + feat_uniq_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The absolute best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>453</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat.N</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.data_path</th>\n",
       "      <td>/mnt/store/hlt/Language/Hungarian/Crawl/Web2/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.encoding</th>\n",
       "      <td>latin2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.last_char</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.sample_per_class</th>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.tag_filter</th>\n",
       "      <td>('NOUN', 'VERB')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.use_padding</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global.comment</th>\n",
       "      <td>include smaller ngrams - first experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global.nolog</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global.train_test_split</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.activations</th>\n",
       "      <td>('sigmoid', 'sigmoid', 'sigmoid')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.architecture</th>\n",
       "      <td>FFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.batch_size</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.input_dim</th>\n",
       "      <td>5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.layers</th>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.loss</th>\n",
       "      <td>binary_crossentropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.metrics</th>\n",
       "      <td>['accuracy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.nb_epoch</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.optimizer</th>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.output_dim</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.exception</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.feature_count</th>\n",
       "      <td>5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.running_time</th>\n",
       "      <td>0 days 00:06:35.295779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.success</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.test_acc</th>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.test_loss</th>\n",
       "      <td>0.0824637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.test_sample_count</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.timestamp</th>\n",
       "      <td>2016-11-28 21:19:13.535698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.train_acc</th>\n",
       "      <td>0.996778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.train_loss</th>\n",
       "      <td>0.01002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.train_sample_count</th>\n",
       "      <td>54000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           453\n",
       "feat.N                                                                       2\n",
       "feat.data_path               /mnt/store/hlt/Language/Hungarian/Crawl/Web2/a...\n",
       "feat.encoding                                                           latin2\n",
       "feat.include_smaller_ngrams                                               True\n",
       "feat.last_char                                                               6\n",
       "feat.sample_per_class                                                    30000\n",
       "feat.tag_filter                                               ('NOUN', 'VERB')\n",
       "feat.use_padding                                                          True\n",
       "global.comment                      include smaller ngrams - first experiments\n",
       "global.nolog                                                             False\n",
       "global.train_test_split                                                    0.9\n",
       "model.activations                            ('sigmoid', 'sigmoid', 'sigmoid')\n",
       "model.architecture                                                        FFNN\n",
       "model.batch_size                                                           500\n",
       "model.input_dim                                                           5510\n",
       "model.layers                                                          (40, 40)\n",
       "model.loss                                                 binary_crossentropy\n",
       "model.metrics                                                     ['accuracy']\n",
       "model.nb_epoch                                                             300\n",
       "model.optimizer                                                        rmsprop\n",
       "model.output_dim                                                             2\n",
       "result.exception                                                           NaN\n",
       "result.feature_count                                                      5510\n",
       "result.running_time                                     0 days 00:06:35.295779\n",
       "result.success                                                            True\n",
       "result.test_acc                                                       0.985333\n",
       "result.test_loss                                                     0.0824637\n",
       "result.test_sample_count                                                  6000\n",
       "result.timestamp                                    2016-11-28 21:19:13.535698\n",
       "result.train_acc                                                      0.996778\n",
       "result.train_loss                                                      0.01002\n",
       "result.train_sample_count                                                54000"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = df.loc[df['result.test_acc'].idxmax()].to_frame().sort_index()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_same_rows(df, lhs, include):\n",
    "    filt = df\n",
    "    for col in df.columns:\n",
    "        if col in include:\n",
    "            filt = filt[filt[col] == lhs[col].values[0]]\n",
    "    return filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "453    0.985333\n",
       "482    0.983833\n",
       "527    0.981833\n",
       "701    0.978833\n",
       "Name: result.test_acc, dtype: float64"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filt = find_same_rows(df, best.transpose(), all_params)['result.test_acc']\n",
    "filt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract NN depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>result.test_acc</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.980937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.001876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.977500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.979438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.981042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.982333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.985083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2</th>\n",
       "      <th>count</th>\n",
       "      <td>454.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.867838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.194320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.007333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.820250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.979229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.980271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.976500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.979000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.980625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.981708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.984000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   result.test_acc\n",
       "model.depth                       \n",
       "1           count        20.000000\n",
       "            mean          0.980937\n",
       "            std           0.001876\n",
       "            min           0.977500\n",
       "            25%           0.979438\n",
       "            50%           0.981042\n",
       "            75%           0.982333\n",
       "            max           0.985083\n",
       "2           count       454.000000\n",
       "            mean          0.867838\n",
       "            std           0.194320\n",
       "            min           0.007333\n",
       "            25%           0.820250\n",
       "            50%           0.960792\n",
       "            75%           0.979229\n",
       "            max           0.985333\n",
       "3           count        24.000000\n",
       "            mean          0.980271\n",
       "            std           0.002118\n",
       "            min           0.976500\n",
       "            25%           0.979000\n",
       "            50%           0.980625\n",
       "            75%           0.981708\n",
       "            max           0.984000"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['model.depth'] = df['model.layers'].apply(lambda x: len(eval(x)))\n",
    "df[['model.depth', 'result.test_acc']].groupby('model.depth').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>feat.N</th>\n",
       "      <th>feat.last_char</th>\n",
       "      <th>feat.sample_per_class</th>\n",
       "      <th>global.train_test_split</th>\n",
       "      <th>model.batch_size</th>\n",
       "      <th>model.input_dim</th>\n",
       "      <th>model.nb_epoch</th>\n",
       "      <th>model.output_dim</th>\n",
       "      <th>result.exception</th>\n",
       "      <th>result.feature_count</th>\n",
       "      <th>result.test_acc</th>\n",
       "      <th>result.test_loss</th>\n",
       "      <th>result.test_sample_count</th>\n",
       "      <th>result.train_acc</th>\n",
       "      <th>result.train_loss</th>\n",
       "      <th>result.train_sample_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.depth</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">1</th>\n",
       "      <th>count</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2.000000e+01</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.980937</td>\n",
       "      <td>0.083297</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.995879</td>\n",
       "      <td>0.013604</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.278130e-16</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001876</td>\n",
       "      <td>0.009713</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001193</td>\n",
       "      <td>0.003963</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.977500</td>\n",
       "      <td>0.067093</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.991519</td>\n",
       "      <td>0.010700</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.979438</td>\n",
       "      <td>0.075706</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.995718</td>\n",
       "      <td>0.011315</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.981042</td>\n",
       "      <td>0.081142</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996370</td>\n",
       "      <td>0.012256</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.982333</td>\n",
       "      <td>0.089413</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996546</td>\n",
       "      <td>0.014515</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.985083</td>\n",
       "      <td>0.102505</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996713</td>\n",
       "      <td>0.028069</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">2</th>\n",
       "      <th>count</th>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.0</td>\n",
       "      <td>4.540000e+02</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.0</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.000000</td>\n",
       "      <td>454.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.292952</td>\n",
       "      <td>6.006608</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>923.953744</td>\n",
       "      <td>5524.246696</td>\n",
       "      <td>201.409692</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5524.246696</td>\n",
       "      <td>0.867838</td>\n",
       "      <td>0.337055</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.885734</td>\n",
       "      <td>0.269259</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.603003</td>\n",
       "      <td>0.453050</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.334343e-16</td>\n",
       "      <td>1627.863840</td>\n",
       "      <td>5240.612819</td>\n",
       "      <td>162.581600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5240.612819</td>\n",
       "      <td>0.194320</td>\n",
       "      <td>0.995919</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.195626</td>\n",
       "      <td>0.999923</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.070530</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.001556</td>\n",
       "      <td>0.001986</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>481.000000</td>\n",
       "      <td>0.820250</td>\n",
       "      <td>0.102275</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.863352</td>\n",
       "      <td>0.011854</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.960792</td>\n",
       "      <td>0.137231</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.967995</td>\n",
       "      <td>0.077770</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.979229</td>\n",
       "      <td>0.290066</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996528</td>\n",
       "      <td>0.214488</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>38028.000000</td>\n",
       "      <td>900.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38028.000000</td>\n",
       "      <td>0.985333</td>\n",
       "      <td>8.244886</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.999222</td>\n",
       "      <td>8.059048</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">3</th>\n",
       "      <th>count</th>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>2.400000e+01</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.980271</td>\n",
       "      <td>0.094823</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996026</td>\n",
       "      <td>0.013492</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002118</td>\n",
       "      <td>0.013571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001183</td>\n",
       "      <td>0.004605</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.976500</td>\n",
       "      <td>0.067788</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.992574</td>\n",
       "      <td>0.009144</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.979000</td>\n",
       "      <td>0.084056</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.995551</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.980625</td>\n",
       "      <td>0.093978</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996407</td>\n",
       "      <td>0.011815</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.981708</td>\n",
       "      <td>0.106334</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.996803</td>\n",
       "      <td>0.014315</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>9.000000e-01</td>\n",
       "      <td>500.000000</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5510.000000</td>\n",
       "      <td>0.984000</td>\n",
       "      <td>0.125698</td>\n",
       "      <td>6000.0</td>\n",
       "      <td>0.997093</td>\n",
       "      <td>0.024609</td>\n",
       "      <td>54000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       feat.N  feat.last_char  feat.sample_per_class  \\\n",
       "model.depth                                                            \n",
       "1           count   20.000000       20.000000                   20.0   \n",
       "            mean     2.000000        6.000000                30000.0   \n",
       "            std      0.000000        0.000000                    0.0   \n",
       "            min      2.000000        6.000000                30000.0   \n",
       "            25%      2.000000        6.000000                30000.0   \n",
       "            50%      2.000000        6.000000                30000.0   \n",
       "            75%      2.000000        6.000000                30000.0   \n",
       "            max      2.000000        6.000000                30000.0   \n",
       "2           count  454.000000      454.000000                  454.0   \n",
       "            mean     2.292952        6.006608                30000.0   \n",
       "            std      1.603003        0.453050                    0.0   \n",
       "            min      1.000000        3.000000                30000.0   \n",
       "            25%      1.000000        6.000000                30000.0   \n",
       "            50%      2.000000        6.000000                30000.0   \n",
       "            75%      2.000000        6.000000                30000.0   \n",
       "            max      6.000000        9.000000                30000.0   \n",
       "3           count   24.000000       24.000000                   24.0   \n",
       "            mean     2.000000        6.000000                30000.0   \n",
       "            std      0.000000        0.000000                    0.0   \n",
       "            min      2.000000        6.000000                30000.0   \n",
       "            25%      2.000000        6.000000                30000.0   \n",
       "            50%      2.000000        6.000000                30000.0   \n",
       "            75%      2.000000        6.000000                30000.0   \n",
       "            max      2.000000        6.000000                30000.0   \n",
       "\n",
       "                   global.train_test_split  model.batch_size  model.input_dim  \\\n",
       "model.depth                                                                     \n",
       "1           count             2.000000e+01         20.000000        20.000000   \n",
       "            mean              9.000000e-01        500.000000      5510.000000   \n",
       "            std               2.278130e-16          0.000000         0.000000   \n",
       "            min               9.000000e-01        500.000000      5510.000000   \n",
       "            25%               9.000000e-01        500.000000      5510.000000   \n",
       "            50%               9.000000e-01        500.000000      5510.000000   \n",
       "            75%               9.000000e-01        500.000000      5510.000000   \n",
       "            max               9.000000e-01        500.000000      5510.000000   \n",
       "2           count             4.540000e+02        454.000000       454.000000   \n",
       "            mean              9.000000e-01        923.953744      5524.246696   \n",
       "            std               3.334343e-16       1627.863840      5240.612819   \n",
       "            min               9.000000e-01         10.000000       250.000000   \n",
       "            25%               9.000000e-01        200.000000       481.000000   \n",
       "            50%               9.000000e-01        500.000000      5510.000000   \n",
       "            75%               9.000000e-01        500.000000      5510.000000   \n",
       "            max               9.000000e-01      10000.000000     38028.000000   \n",
       "3           count             2.400000e+01         24.000000        24.000000   \n",
       "            mean              9.000000e-01        500.000000      5510.000000   \n",
       "            std               0.000000e+00          0.000000         0.000000   \n",
       "            min               9.000000e-01        500.000000      5510.000000   \n",
       "            25%               9.000000e-01        500.000000      5510.000000   \n",
       "            50%               9.000000e-01        500.000000      5510.000000   \n",
       "            75%               9.000000e-01        500.000000      5510.000000   \n",
       "            max               9.000000e-01        500.000000      5510.000000   \n",
       "\n",
       "                   model.nb_epoch  model.output_dim  result.exception  \\\n",
       "model.depth                                                             \n",
       "1           count       20.000000              20.0               0.0   \n",
       "            mean       300.000000               2.0               NaN   \n",
       "            std          0.000000               0.0               NaN   \n",
       "            min        300.000000               2.0               NaN   \n",
       "            25%        300.000000               2.0               NaN   \n",
       "            50%        300.000000               2.0               NaN   \n",
       "            75%        300.000000               2.0               NaN   \n",
       "            max        300.000000               2.0               NaN   \n",
       "2           count      454.000000             454.0               0.0   \n",
       "            mean       201.409692               2.0               NaN   \n",
       "            std        162.581600               0.0               NaN   \n",
       "            min          5.000000               2.0               NaN   \n",
       "            25%         60.000000               2.0               NaN   \n",
       "            50%        300.000000               2.0               NaN   \n",
       "            75%        300.000000               2.0               NaN   \n",
       "            max        900.000000               2.0               NaN   \n",
       "3           count       24.000000              24.0               0.0   \n",
       "            mean       300.000000               2.0               NaN   \n",
       "            std          0.000000               0.0               NaN   \n",
       "            min        300.000000               2.0               NaN   \n",
       "            25%        300.000000               2.0               NaN   \n",
       "            50%        300.000000               2.0               NaN   \n",
       "            75%        300.000000               2.0               NaN   \n",
       "            max        300.000000               2.0               NaN   \n",
       "\n",
       "                   result.feature_count  result.test_acc  result.test_loss  \\\n",
       "model.depth                                                                  \n",
       "1           count             20.000000        20.000000         20.000000   \n",
       "            mean            5510.000000         0.980937          0.083297   \n",
       "            std                0.000000         0.001876          0.009713   \n",
       "            min             5510.000000         0.977500          0.067093   \n",
       "            25%             5510.000000         0.979438          0.075706   \n",
       "            50%             5510.000000         0.981042          0.081142   \n",
       "            75%             5510.000000         0.982333          0.089413   \n",
       "            max             5510.000000         0.985083          0.102505   \n",
       "2           count            454.000000       454.000000        454.000000   \n",
       "            mean            5524.246696         0.867838          0.337055   \n",
       "            std             5240.612819         0.194320          0.995919   \n",
       "            min              250.000000         0.007333          0.070530   \n",
       "            25%              481.000000         0.820250          0.102275   \n",
       "            50%             5510.000000         0.960792          0.137231   \n",
       "            75%             5510.000000         0.979229          0.290066   \n",
       "            max            38028.000000         0.985333          8.244886   \n",
       "3           count             24.000000        24.000000         24.000000   \n",
       "            mean            5510.000000         0.980271          0.094823   \n",
       "            std                0.000000         0.002118          0.013571   \n",
       "            min             5510.000000         0.976500          0.067788   \n",
       "            25%             5510.000000         0.979000          0.084056   \n",
       "            50%             5510.000000         0.980625          0.093978   \n",
       "            75%             5510.000000         0.981708          0.106334   \n",
       "            max             5510.000000         0.984000          0.125698   \n",
       "\n",
       "                   result.test_sample_count  result.train_acc  \\\n",
       "model.depth                                                     \n",
       "1           count                      20.0         20.000000   \n",
       "            mean                     6000.0          0.995879   \n",
       "            std                         0.0          0.001193   \n",
       "            min                      6000.0          0.991519   \n",
       "            25%                      6000.0          0.995718   \n",
       "            50%                      6000.0          0.996370   \n",
       "            75%                      6000.0          0.996546   \n",
       "            max                      6000.0          0.996713   \n",
       "2           count                     454.0        454.000000   \n",
       "            mean                     6000.0          0.885734   \n",
       "            std                         0.0          0.195626   \n",
       "            min                      6000.0          0.001556   \n",
       "            25%                      6000.0          0.863352   \n",
       "            50%                      6000.0          0.967995   \n",
       "            75%                      6000.0          0.996528   \n",
       "            max                      6000.0          0.999222   \n",
       "3           count                      24.0         24.000000   \n",
       "            mean                     6000.0          0.996026   \n",
       "            std                         0.0          0.001183   \n",
       "            min                      6000.0          0.992574   \n",
       "            25%                      6000.0          0.995551   \n",
       "            50%                      6000.0          0.996407   \n",
       "            75%                      6000.0          0.996803   \n",
       "            max                      6000.0          0.997093   \n",
       "\n",
       "                   result.train_loss  result.train_sample_count  \n",
       "model.depth                                                      \n",
       "1           count          20.000000                       20.0  \n",
       "            mean            0.013604                    54000.0  \n",
       "            std             0.003963                        0.0  \n",
       "            min             0.010700                    54000.0  \n",
       "            25%             0.011315                    54000.0  \n",
       "            50%             0.012256                    54000.0  \n",
       "            75%             0.014515                    54000.0  \n",
       "            max             0.028069                    54000.0  \n",
       "2           count         454.000000                      454.0  \n",
       "            mean            0.269259                    54000.0  \n",
       "            std             0.999923                        0.0  \n",
       "            min             0.001986                    54000.0  \n",
       "            25%             0.011854                    54000.0  \n",
       "            50%             0.077770                    54000.0  \n",
       "            75%             0.214488                    54000.0  \n",
       "            max             8.059048                    54000.0  \n",
       "3           count          24.000000                       24.0  \n",
       "            mean            0.013492                    54000.0  \n",
       "            std             0.004605                        0.0  \n",
       "            min             0.009144                    54000.0  \n",
       "            25%             0.010306                    54000.0  \n",
       "            50%             0.011815                    54000.0  \n",
       "            75%             0.014315                    54000.0  \n",
       "            max             0.024609                    54000.0  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('model.depth').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw = False\n",
    "\n",
    "if draw:\n",
    "    f = df[df['feat.sample_per_class'] > 10000]\n",
    "    batches = df['model.batch_size'].unique()\n",
    "\n",
    "    for key, val in f.groupby(features):\n",
    "        for nb in batches:\n",
    "            filt = val[val['model.batch_size'] == nb]\n",
    "            if len(filt) == 0:\n",
    "                continue\n",
    "            if filt['result.test_acc'].max() < 0.95:\n",
    "                continue\n",
    "            filt = filt.groupby('model.nb_epoch').mean()\n",
    "            filt[filt['model.batch_size'] == nb].plot(y='result.test_acc', kind='bar',\n",
    "                                                    ylim=(.9, 1), title=\"Epoch: {}, last_char: {} Sample: {} N: {}\".format(\n",
    "                    nb, key[0], key[5], key[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
