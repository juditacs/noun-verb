{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')\n",
    "plt.rcParams['figure.figsize'] = (25, 13)\n",
    "plt.rcParams['font.family'] = 'sans-serif'\n",
    "plt.rcParams['font.size'] = 20\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful: 472\n",
      "Failed: 0\n",
      "Filtering failed experiments.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_table('results.tsv', sep='\\t')\n",
    "print(\"Successful: {}\\nFailed: {}\".format(len(df[df['result.success'] == True]), len(df[df['result.success'] == False])))\n",
    "\n",
    "print(\"Filtering failed experiments.\")\n",
    "df = df[df['result.success'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_varying_columns(df, prefix=None):\n",
    "    out_cols = []\n",
    "    filtered_cols = df.columns\n",
    "    if prefix is not None:\n",
    "        filtered_cols = filter(lambda x: x.startswith(prefix), filtered_cols)\n",
    "    for col in filtered_cols:\n",
    "        if df[col].unique().shape[0] > 1:\n",
    "            out_cols.append(col)\n",
    "    return out_cols\n",
    "\n",
    "def get_too_varying_columns(df, prefix=None, threshold=0.95):\n",
    "    out_cols = []\n",
    "    filtered_cols = df.columns\n",
    "    if prefix is not None:\n",
    "        filtered_cols = filter(lambda x: x.startswith(prefix), cols)\n",
    "    for col in filtered_cols:\n",
    "        uniq_vals = df[col].unique().shape[0]\n",
    "        if uniq_vals > threshold * len(df):\n",
    "            out_cols.append(col)\n",
    "    return out_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "feat_uniq_col = get_varying_columns(df, 'feat.')\n",
    "result_uniq_col = get_varying_columns(df, 'result.')\n",
    "model_uniq_col = get_varying_columns(df, 'model.')\n",
    "non_monoton = get_varying_columns(df)\n",
    "uninteresting_columns = filter(lambda x: x not in non_monoton, df.columns)\n",
    "ignore_cols = [\n",
    "    'result.train_loss', 'result.test_loss', 'result.timestamp', 'result.running_time',\n",
    "]\n",
    "result_uniq_col = [col for col in result_uniq_col if col not in ignore_cols]\n",
    "interesting_columns = result_uniq_col + feat_uniq_col + model_uniq_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unique feature combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat.use_padding</th>\n",
       "      <th>feat.sample_per_class</th>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <th>feat.N</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>True</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>336</th>\n",
       "      <td>False</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>402</th>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat.use_padding  feat.sample_per_class feat.include_smaller_ngrams  \\\n",
       "0               True                10000.0                       False   \n",
       "72              True                10000.0                       False   \n",
       "204             True                30000.0                       False   \n",
       "336            False                30000.0                       False   \n",
       "402             True                30000.0                       False   \n",
       "432             True                30000.0                        True   \n",
       "\n",
       "     feat.N  \n",
       "0       2.0  \n",
       "72      1.0  \n",
       "204     1.0  \n",
       "336     6.0  \n",
       "402     2.0  \n",
       "432     2.0  "
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[feature_col].drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of experiments per combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>model.nb_epoch</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.use_padding</th>\n",
       "      <th>feat.sample_per_class</th>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <th>feat.N</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>False</th>\n",
       "      <th>30000.0</th>\n",
       "      <th>False</th>\n",
       "      <th>6.0</th>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">True</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">10000.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>1.0</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">30000.0</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">False</th>\n",
       "      <th>1.0</th>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True</th>\n",
       "      <th>2.0</th>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           model.nb_epoch\n",
       "feat.use_padding feat.sample_per_class feat.include_smaller_ngrams feat.N                \n",
       "False            30000.0               False                       6.0                 66\n",
       "True             10000.0               False                       1.0                132\n",
       "                                                                   2.0                 72\n",
       "                 30000.0               False                       1.0                132\n",
       "                                                                   2.0                 30\n",
       "                                       True                        2.0                 40"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(feature_col).count()['model.nb_epoch'].to_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Maximum test accuracy by feature combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>result.test_acc</th>\n",
       "      <th>feat.use_padding</th>\n",
       "      <th>feat.sample_per_class</th>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <th>feat.N</th>\n",
       "      <th>model.nb_epoch</th>\n",
       "      <th>model.batch_size</th>\n",
       "      <th>model.input_dim</th>\n",
       "      <th>model.layers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0.819917</td>\n",
       "      <td>False</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>6.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>14036.0</td>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>0.945750</td>\n",
       "      <td>True</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>396.0</td>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.966000</td>\n",
       "      <td>True</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>3604.0</td>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>0.973417</td>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>481.0</td>\n",
       "      <td>(100, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>429</th>\n",
       "      <td>0.979500</td>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>2.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>3000.0</td>\n",
       "      <td>5029.0</td>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>0.985333</td>\n",
       "      <td>True</td>\n",
       "      <td>30000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>2.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>500.0</td>\n",
       "      <td>5510.0</td>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     result.test_acc feat.use_padding  feat.sample_per_class  \\\n",
       "359         0.819917            False                30000.0   \n",
       "198         0.945750             True                10000.0   \n",
       "39          0.966000             True                10000.0   \n",
       "325         0.973417             True                30000.0   \n",
       "429         0.979500             True                30000.0   \n",
       "453         0.985333             True                30000.0   \n",
       "\n",
       "    feat.include_smaller_ngrams  feat.N  model.nb_epoch  model.batch_size  \\\n",
       "359                       False     6.0            30.0            2000.0   \n",
       "198                       False     1.0           100.0              50.0   \n",
       "39                        False     2.0            50.0             500.0   \n",
       "325                       False     1.0            90.0             100.0   \n",
       "429                       False     2.0           900.0            3000.0   \n",
       "453                        True     2.0           300.0             500.0   \n",
       "\n",
       "     model.input_dim model.layers  \n",
       "359          14036.0     (40, 40)  \n",
       "198            396.0     (40, 40)  \n",
       "39            3604.0     (40, 40)  \n",
       "325            481.0    (100, 40)  \n",
       "429           5029.0     (40, 40)  \n",
       "453           5510.0     (40, 40)  "
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAg4AAAF2CAYAAAAGIhAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0feffff5c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_rows = df.iloc[df.groupby(feature_col).idxmax()['result.test_acc'].astype(int)]\n",
    "max_rows.plot(y='result.test_acc', kind='bar', ylim=(0.95, 1))\n",
    "max_rows[['result.test_acc'] + feat_uniq_col + model_uniq_col]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The absolute best combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>453</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>feat.N</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.data_path</th>\n",
       "      <td>/mnt/store/hlt/Language/Hungarian/Crawl/Web2/a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.encoding</th>\n",
       "      <td>latin2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.include_smaller_ngrams</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.last_char</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.sample_per_class</th>\n",
       "      <td>30000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.tag_filter</th>\n",
       "      <td>('NOUN', 'VERB')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>feat.use_padding</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global.comment</th>\n",
       "      <td>include smaller ngrams - first experiments</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global.nolog</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global.train_test_split</th>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.activations</th>\n",
       "      <td>('sigmoid', 'sigmoid', 'sigmoid')</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.architecture</th>\n",
       "      <td>FFNN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.batch_size</th>\n",
       "      <td>500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.input_dim</th>\n",
       "      <td>5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.layers</th>\n",
       "      <td>(40, 40)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.loss</th>\n",
       "      <td>binary_crossentropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.metrics</th>\n",
       "      <td>['accuracy']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.nb_epoch</th>\n",
       "      <td>300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.optimizer</th>\n",
       "      <td>rmsprop</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>model.output_dim</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.exception</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.feature_count</th>\n",
       "      <td>5510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.running_time</th>\n",
       "      <td>0 days 00:06:35.295779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.success</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.test_acc</th>\n",
       "      <td>0.985333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.test_loss</th>\n",
       "      <td>0.0824637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.test_sample_count</th>\n",
       "      <td>6000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.timestamp</th>\n",
       "      <td>2016-11-28 21:19:13.535698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.train_acc</th>\n",
       "      <td>0.996778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.train_loss</th>\n",
       "      <td>0.01002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>result.train_sample_count</th>\n",
       "      <td>54000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                           453\n",
       "feat.N                                                                       2\n",
       "feat.data_path               /mnt/store/hlt/Language/Hungarian/Crawl/Web2/a...\n",
       "feat.encoding                                                           latin2\n",
       "feat.include_smaller_ngrams                                               True\n",
       "feat.last_char                                                               6\n",
       "feat.sample_per_class                                                    30000\n",
       "feat.tag_filter                                               ('NOUN', 'VERB')\n",
       "feat.use_padding                                                          True\n",
       "global.comment                      include smaller ngrams - first experiments\n",
       "global.nolog                                                             False\n",
       "global.train_test_split                                                    0.9\n",
       "model.activations                            ('sigmoid', 'sigmoid', 'sigmoid')\n",
       "model.architecture                                                        FFNN\n",
       "model.batch_size                                                           500\n",
       "model.input_dim                                                           5510\n",
       "model.layers                                                          (40, 40)\n",
       "model.loss                                                 binary_crossentropy\n",
       "model.metrics                                                     ['accuracy']\n",
       "model.nb_epoch                                                             300\n",
       "model.optimizer                                                        rmsprop\n",
       "model.output_dim                                                             2\n",
       "result.exception                                                           NaN\n",
       "result.feature_count                                                      5510\n",
       "result.running_time                                     0 days 00:06:35.295779\n",
       "result.success                                                            True\n",
       "result.test_acc                                                       0.985333\n",
       "result.test_loss                                                     0.0824637\n",
       "result.test_sample_count                                                  6000\n",
       "result.timestamp                                    2016-11-28 21:19:13.535698\n",
       "result.train_acc                                                      0.996778\n",
       "result.train_loss                                                      0.01002\n",
       "result.train_sample_count                                                54000"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best = df.iloc[df['result.test_acc'].idxmax()].to_frame().sort_index()\n",
    "best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "500.0    8\n",
       "400.0    8\n",
       "300.0    8\n",
       "200.0    8\n",
       "100.0    8\n",
       "Name: model.nb_epoch, dtype: int64"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df['feat.include_smaller_ngrams'] == True]['model.nb_epoch'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def find_same_rows(df, lhs, include):\n",
    "    filt = df\n",
    "    for col in df.columns:\n",
    "        if col in include:\n",
    "            filt = filt[filt[col] == lhs[col].values[0]]\n",
    "    return filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "filt = find_same_rows(df, best.transpose(), feat_uniq_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "draw = False\n",
    "\n",
    "if draw:\n",
    "    f = df[df['feat.sample_per_class'] > 10000]\n",
    "    batches = df['model.batch_size'].unique()\n",
    "\n",
    "    for key, val in f.groupby(features):\n",
    "        for nb in batches:\n",
    "            filt = val[val['model.batch_size'] == nb]\n",
    "            if len(filt) == 0:\n",
    "                continue\n",
    "            if filt['result.test_acc'].max() < 0.95:\n",
    "                continue\n",
    "            filt = filt.groupby('model.nb_epoch').mean()\n",
    "            filt[filt['model.batch_size'] == nb].plot(y='result.test_acc', kind='bar',\n",
    "                                                    ylim=(.9, 1), title=\"Epoch: {}, last_char: {} Sample: {} N: {}\".format(\n",
    "                    nb, key[0], key[5], key[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
